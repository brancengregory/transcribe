[{"path":[]},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"install-the-package","dir":"Articles","previous_headings":"Installation","what":"1. Install the Package","title":"Introduction","text":"Install transcribe GitHub:","code":"# Uncomment if needed: # install.packages(\"remotes\") remotes::install_github(\"brancengregory/transcribe\")"},{"path":[]},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"on-macos","dir":"Articles","previous_headings":"Installation > 2. Install Python Dependencies (Whisper)","what":"On macOS:","title":"Introduction","text":"Homebrew: Ensure Homebrew installed. , visit brew.sh instructions. , install Python (needed) use pip install Whisper: yt-dlp: Install via Homebrew:","code":"brew install python3 pip3 install openai-whisper brew install yt-dlp"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"on-linux","dir":"Articles","previous_headings":"Installation > 2. Install Python Dependencies (Whisper)","what":"On Linux:","title":"Introduction","text":"Python: Ensure Python 3 installed. Ubuntu/Debian: yt-dlp: can install via pip package manager: ","code":"sudo apt-get update sudo apt-get install python3 python3-pip pip3 install openai-whisper pip3 install yt-dlp sudo apt-get install yt-dlp"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"install-and-run-ollama","dir":"Articles","previous_headings":"Installation","what":"3. Install and Run Ollama","title":"Introduction","text":"macOS: Check Ollama’s website use Homebrew available: Linux: Follow installation instructions provided Ollama’s documentation (available) consider alternatives Ollama supported.","code":"brew install ollama ollama run"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"additional-dependencies","dir":"Articles","previous_headings":"Installation","what":"4. Additional Dependencies","title":"Introduction","text":"package uses: - processx wrap external commands (e.g., yt-dlp), - reticulate call Python’s Whisper, - ellmer prompt-based post‑processing transcripts, - curl URL encoding/decoding. Ensure packages installed R:","code":"install.packages(c(\"processx\", \"reticulate\", \"ellmer\", \"curl\", \"logger\", \"glue\", \"stringr\", \"fs\"))"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"how-it-works","dir":"Articles","previous_headings":"","what":"How It Works","title":"Introduction","text":"Audio Downloading: given remote URL, processx calls yt-dlp download audio file WAV format. Transcription via Whisper: Python’s Whisper accessed via reticulate transcribe audio. Post‑processing Ollama ellmer: raw transcript Whisper optionally cleaned using prompt via ellmer, sends text Ollama server formatting. Interfaces: CLI: Process audio via command-line scripts. Plumber API: web-based interface uploading files entering URLs.","code":""},{"path":[]},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"transcribing-a-local-file","dir":"Articles","previous_headings":"Basic Usage","what":"Transcribing a Local File","title":"Introduction","text":"","code":"library(transcribe)  transcript <- transcribe_audio(   input_path = \"path/to/audio.wav\",   language = \"en\",   whisper_model_name = \"large-v3-turbo\",   processed = TRUE,   ollama_model = \"llama3.2\" ) cat(transcript)"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"transcribing-an-online-video","dir":"Articles","previous_headings":"Basic Usage","what":"Transcribing an Online Video","title":"Introduction","text":"","code":"transcript <- transcribe_audio(   input_path = \"https://www.youtube.com/watch?v=lT4Kosc_ers\",   language = \"en\",   whisper_model_name = \"large-v3-turbo\",   processed = TRUE,   ollama_model = \"llama3.2\" )"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"cli-usage","dir":"Articles","previous_headings":"","what":"CLI Usage","title":"Introduction","text":"package provides command‑line interface. example, run: command processes audio file saves transcript transcribe.txt.","code":"Rscript inst/scripts/main_cli.R -i \"path/to/audio.wav\" -l en -m large-v3-turbo -p TRUE -M llama3.2 -o \"transcribe.txt\""},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"plumber-api","dir":"Articles","previous_headings":"","what":"Plumber API","title":"Introduction","text":"can also run web interface via Plumber: open browser http://127.0.0.1:7608 access transcription interface.","code":"library(plumber) plumber::plumb(\"inst/plumber/api.R\")$run(port = 7608)"},{"path":[]},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"audio-downloading","dir":"Articles","previous_headings":"Technical Breakdown","what":"Audio Downloading","title":"Introduction","text":"processx wraps yt-dlp download convert audio files.","code":""},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"transcription","dir":"Articles","previous_headings":"Technical Breakdown","what":"Transcription","title":"Introduction","text":"reticulate used invoke Python’s Whisper, providing state‑‑‑art transcription engine.","code":""},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"postprocessing","dir":"Articles","previous_headings":"Technical Breakdown","what":"Post‑processing","title":"Introduction","text":"ellmer sends raw transcript Ollama prompt reformat clean .","code":""},{"path":[]},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"out-of-memory-errors","dir":"Articles","previous_headings":"Troubleshooting","what":"Out of Memory Errors","title":"Introduction","text":"Purge model cache Ollama transcription needed: Consider using smaller Whisper model (e.g., “tiny” “base”) VRAM limited.","code":"ollama purge --model llama3.2"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"yt-dlp-issues","dir":"Articles","previous_headings":"Troubleshooting","what":"yt-dlp Issues","title":"Introduction","text":"Update yt-dlp:","code":"yt-dlp --update"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"ollama-not-running","dir":"Articles","previous_headings":"Troubleshooting","what":"Ollama Not Running","title":"Introduction","text":"Ensure Ollama started:","code":"ollama run"},{"path":"https://brancengregory.github.io/transcribe/articles/intro.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Introduction","text":"transcribe package provides flexible R-based solution audio transcription cleanup, using Whisper, yt-dlp, Ollama. supports multiple interfaces (CLI web) offers robust workflow local online audio sources. details, please refer package documentation additional vignettes. Happy transcribing!","code":"vignette(\"intro\", package = \"transcribe\")"},{"path":"https://brancengregory.github.io/transcribe/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"https://brancengregory.github.io/transcribe/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2025). transcribe: Package (One Line, Title Case). R package version 0.0.0.9001, https://brancengregory.github.io/transcribe/.","code":"@Manual{,   title = {transcribe: What the Package Does (One Line, Title Case)},   author = {First Last},   year = {2025},   note = {R package version 0.0.0.9001},   url = {https://brancengregory.github.io/transcribe/}, }"},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"transcribe-","dir":"","previous_headings":"","what":"What the Package Does (One Line, Title Case)","title":"What the Package Does (One Line, Title Case)","text":"transcribe package provides R interface audio transcription using Whisper, optional post‑processing via Ollama. includes command‑line interface (CLI) Plumber API create web interface.","code":""},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"prerequisites","dir":"","previous_headings":"","what":"Prerequisites","title":"What the Package Does (One Line, Title Case)","text":"Whisper: Make sure OpenAI Whisper installed configured. Follow official documentation installation instructions. Ollama: Ensure Ollama installed running. Consult Ollama documentation setup details configuration. Dependencies: package uses: processx wrap yt-dlp command downloading audio files. reticulate call Python’s Whisper implementation. ellmer prompt-based post‑processing raw Whisper transcripts. Please refer package’s documentation details.","code":""},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"What the Package Does (One Line, Title Case)","text":"package workflow follows: Audio Downloading: given remote URL, processx used call yt-dlp, downloading audio file quickly robustly. Transcription via Whisper: Python’s Whisper called via reticulate, providing state‑‑‑art transcription directly R. Post‑processing Ollama ellmer: raw transcript Whisper optionally sent Ollama via ellmer using prompt (e.g., “Reformat transcript clear, well‑punctuated paragraphs…”) produce cleaned, readable transcript. Interfaces: Use CLI batch processing, launch Plumber API access web interface.","code":""},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"What the Package Does (One Line, Title Case)","text":"","code":"# install.packages(\"remotes\") # if not already installed remotes::install_github(\"brancengregory/transcribe\")"},{"path":[]},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"basic-example","dir":"","previous_headings":"Usage","what":"Basic Example","title":"What the Package Does (One Line, Title Case)","text":"","code":"library(transcribe)  # Transcribe a local audio file. transcript <- transcribe_audio(   input_path = \"path/to/audio.wav\",   language = \"en\",   whisper_model_name = \"large-v3-turbo\",   processed = TRUE,   ollama_model = \"llama3.2\" ) cat(transcript)"},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"cli-usage","dir":"","previous_headings":"Usage","what":"CLI Usage","title":"What the Package Does (One Line, Title Case)","text":"use command‑line interface, run following command terminal: command processes specified audio file saves transcript transcribe.txt.","code":"Rscript inst/scripts/main_cli.R -i \"path/to/audio.wav\" -l en -m large-v3-turbo -p TRUE -M llama3.2 -o \"transcribe.txt\""},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"plumber-api","dir":"","previous_headings":"Usage","what":"Plumber API","title":"What the Package Does (One Line, Title Case)","text":"can serve web interface via plumber. example: open browser http://127.0.0.1:7608 use transcription interface.","code":"library(plumber) plumber::plumb(\"inst/plumber/api.R\")$run(port = 7608)"},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"What the Package Does (One Line, Title Case)","text":"detailed introduction, see vignette “intro”:","code":"vignette(\"intro\", package = \"transcribe\")"},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"What the Package Does (One Line, Title Case)","text":"Fork repository GitHub. Create new branch changes. Submit pull request describing proposed changes.","code":""},{"path":"https://brancengregory.github.io/transcribe/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"What the Package Does (One Line, Title Case)","text":"MIT © 2025 Name","code":""},{"path":"https://brancengregory.github.io/transcribe/reference/allowed_whisper_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Whisper models for transcription. — allowed_whisper_models","title":"Allowed Whisper models for transcription. — allowed_whisper_models","text":"Allowed Whisper models transcription.","code":""},{"path":"https://brancengregory.github.io/transcribe/reference/allowed_whisper_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Whisper models for transcription. — allowed_whisper_models","text":"","code":"allowed_whisper_models"},{"path":"https://brancengregory.github.io/transcribe/reference/allowed_whisper_models.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Whisper models for transcription. — allowed_whisper_models","text":"object class character length 6.","code":""}]
